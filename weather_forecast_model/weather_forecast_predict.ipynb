{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install --upgrade pandas\n",
    "!pip3 install --upgrade sklearn\n",
    "!pip3 install --upgrade pymysql\n",
    "!pip3 install --upgrade pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "from keras.models import load_model\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import pymysql\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database connection init\n",
    "conn=pymysql.connect(\n",
    "    host='sql10.freemysqlhosting.net',\n",
    "    port=int(3306),\n",
    "    user='sql10489794',\n",
    "    passwd='IPELfw5A2X',\n",
    "    db='sql10489794'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch weather data from visualcrossing.com\n",
    "time_now = datetime.datetime.now(tz=pytz.timezone(\"Europe/Berlin\"))\n",
    "key = \"JPRR7UQ66H89YQ23GM3TYFWBU\"\n",
    "date_start = (time_now - datetime.timedelta(days=2)).strftime(\"%Y-%m-%d\") \n",
    "date_stop  = (time_now).strftime(\"%Y-%m-%d\")\n",
    "result = requests.get(f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/krak%C3%B3w/{date_start}/{date_stop}?unitGroup=metric&include=hours&key={key}&contentType=json\")\n",
    "json_dict = json.loads(str(result.content.decode('utf-8')))\n",
    "new_dict = {}\n",
    "\n",
    "# reshape dictionary for further processing\n",
    "i = 0\n",
    "for day in json_dict['days'][::-1]:\n",
    "    for hour in day['hours'][::-1]:\n",
    "        # leave only relavant data\n",
    "        if day['datetime'] != time_now.strftime(\"%Y-%m-%d\") or hour['datetime'] < time_now.strftime(\"%H:%M:00\"):\n",
    "            new_dict[i] = hour.copy()\n",
    "            # set time in specific format\n",
    "            new_dict[i]['datetime'] = day['datetime'] + 'T' + hour['datetime']\n",
    "            # fetch weather measurements from arduino database\n",
    "            query = f\"SELECT * FROM esp WHERE weather_time = '{day['datetime']}' AND hour = '{hour['datetime'].split(':')[0]}'\"\n",
    "            esp_measurement=pd.read_sql_query(query, conn)\n",
    "            if not esp_measurement.empty:\n",
    "                print(esp_measurement)\n",
    "                new_dict[i]['temp'] = esp_measurement['temperature'][0]\n",
    "                new_dict[i]['humidity'] = esp_measurement['humidity'][0]\n",
    "            i=i+1\n",
    "\n",
    "# change shape            \n",
    "measured_data_wlabels = pd.DataFrame.from_dict(new_dict).transpose()[:48][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_data_wlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = [col for col in measured_data_wlabels]\n",
    "\n",
    "pd.DataFrame(columns_names, columns=['column_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "sc = joblib.load(\"scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [2, 4, 21]\n",
    "selected_columns_names = [columns_names[col] for col in selected_columns]\n",
    "print(selected_columns_names)\n",
    "\n",
    "measured_data_wlabels = measured_data_wlabels.iloc[:,selected_columns]\n",
    "\n",
    "# perform one-hot encoding of weather conditions\n",
    "cond = ['Snow', 'Rain, Partially cloudy', 'Snow, Partially cloudy', 'Rain', 'Partially cloudy', 'Rain, Overcast', 'Snow, Rain, Overcast', 'Overcast', 'Snow, Overcast', 'Clear', 'Snow, Rain, Partially cloudy']\n",
    "for label in cond:\n",
    "    measured_data_wlabels[label] = 0\n",
    "    measured_data_wlabels.loc[measured_data_wlabels['conditions']==label, label] = 1\n",
    "measured_data_wlabels = measured_data_wlabels.drop(columns='conditions')\n",
    "\n",
    "measured_data = measured_data_wlabels.values\n",
    "\n",
    "measured_data = sc.transform(measured_data)\n",
    "measured_data = np.array(measured_data)\n",
    "measured_data = np.reshape(measured_data,(1,measured_data.shape[1],measured_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xzf weather_forecast_model.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weather_forecast_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict weather with precomputed model\n",
    "predicted_weather = model.predict(measured_data)\n",
    "predicted_weather = np.reshape(predicted_weather, (predicted_weather.shape[2],predicted_weather.shape[1]))\n",
    "predicted_weather = sc.inverse_transform(predicted_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore conditions from one-hot encoding\n",
    "predicted_weather_wlabels = pd.DataFrame(predicted_weather, columns=[col for col in selected_columns_names if col != 'conditions']+cond)\n",
    "max_cond = np.argmax(predicted_weather[:, 2:], axis=1)\n",
    "for i, mcond in enumerate(max_cond):\n",
    "    predicted_weather_wlabels.loc[i, 'conditions'] = cond[mcond]\n",
    "predicted_weather_wlabels = predicted_weather_wlabels.drop(columns=cond)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add datetime for storing purposes\n",
    "predicted_weather_wlabels['datetime'] = [(time_now + datetime.timedelta(hours=i+1)).strftime(\"%Y-%m-%dT%H:00:00\") for i in range(12)]\n",
    "column_to_move = predicted_weather_wlabels.pop(\"datetime\")\n",
    "predicted_weather_wlabels.insert(0, \"datetime\", column_to_move)\n",
    "predicted_weather_wlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# push forecast to remote database\n",
    "cursor = conn.cursor()\n",
    "query = \"INSERT INTO forecast (date, hour, temp, humidity, conditions) VALUES \" + \", \".join([\"('{}', '{}', {}, {}, '{}')\".format(row[1]['datetime'].split(\"T\")[0], row[1]['datetime'].split(\"T\")[1], int(row[1]['temp']), int(row[1]['humidity']), row[1]['conditions']) for row in predicted_weather_wlabels[::-1].iterrows()])\n",
    "print(query)\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "cursor.execute(f\"DELETE FROM forecast WHERE id < {cursor.lastrowid}\")\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
